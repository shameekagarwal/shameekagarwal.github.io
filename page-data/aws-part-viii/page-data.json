{"componentChunkName":"component---src-templates-blog-js","path":"/aws-part-viii/","result":{"data":{"markdownRemark":{"fields":{"slug":"/aws-part-viii/"},"id":"a3c71bef-ce4c-5080-91ad-c2b00e6354b2","html":"<h1 id=\"lambda\" style=\"position:relative;\"><a href=\"#lambda\" aria-label=\"lambda permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Lambda</h1>\n<ul>\n<li>event driven architecture - producers and consumers for events. neither of them wait for one another i.e. it is asynchronous. there is an ‚Äúevent router‚Äù and an ‚Äúevent bus‚Äù in between that help receive / deliver messages</li>\n<li>lambda - faas (function as a service)</li>\n<li>we can only specify the amount of memory, and the amount of cpu is provisioned based on the memory. the memory we specify can be between 128mb to 10240mb, and for every 1769mb, we get 1vcpu</li>\n<li>we can create custom runtimes as well. this is achieved like building images in docker</li>\n<li>we can use the temporary storage at /tmp which is 512mb (can be increased upto 10240mb)</li>\n<li>lambda functions have a timeout of 15 minutes, so for workloads that take longer, we cannot use lambda</li>\n<li>use cases -\n<ul>\n<li>file processing - s3 + lambda</li>\n<li>database triggers - dynamodb streams + lambda</li>\n<li>serverless cron - cloudwatch events / event bridge + lambda</li>\n<li>realtime stream data processing - kinesis streams + lambda</li>\n</ul>\n</li>\n<li>lambda has two networking modes -\n<ul>\n<li>public mode - default. it can use public internet and public aws services. but, they cannot access aws services inside a vpc like rds unless allowed to. the performance here is better as well</li>\n<li>vpc mode - runs inside a vpc. so for access to aws public services, we might need things like vpc endpoints / to access public internet, we might need things like nat gateway. behind the scenes, like in fargate, the lambda functions run inside the aws public vpc and a network interface in our vpc is used. historically, an endpoint was created for every new lambda invocation, so 6 interfaces for 3 functions with two invocations happening concurrently. this made management difficult and consumed a lot of ip addresses of vpc as well. an optimization was introduced, where an eni is created for every subnet + security group unique combination. this also means that a new eni is not created everytime the function is invoked like earlier, it happens beforehand when we configure networking</li>\n</ul>\n</li>\n<li>lambda functions have an execution role which can be permissions for functions to interact with aws. the trust policy of this role is lambda, and the permissions policy defines what aws services it can interact with</li>\n<li>when using kms, the resource policy of the key needs to allow permission to this execution role as well apart from just the execution role having the permission to use the key</li>\n<li>lambda also has resource policy - allows external accounts / aws services to invoke lambda</li>\n<li>logging - lambda uses cloudwatch and xray for monitoring</li>\n<li>to log into cloudwatch, we need to give the lambda execution role the right policies. my understanding - a managed aws policy already exists for this</li>\n<li>lambda can be invoked using -\n<ul>\n<li>synchronous invocation - wait for a response from lambda. e.g. when invoking via aws apis, api gateway, etc. the errors and retries need to be handled by the client</li>\n<li>asynchronous invocation - usually when aws services invoke lambda, e.g. s3 events. s3 does not wait for lambda. lambda can retry in case of failure (the value can be 0-2). note -  the function should be idempotent to avoid invalid final states. lambda can send events which it failed to process (event after retries) to a dlq. a new feature called <u>destinations</u> is supported i.e. aws sends processed events to sqs, sns, cloudwatch, etc. my understanding - destinations <u>can be separate for failed vs success</u></li>\n<li>event source mapping - streams or queues which do not support invoking lambda, e.g. sqs, kinesis, dynamodb streams. a polling is required here. so, an <u>event source mapper</u> polls for this data and invokes lambda using a batch of data. here too, there is a dlq support for failed batches. some considerations -\n<ul>\n<li>batch size should not be too high, recall how lambda has a timeout of 15 minutes</li>\n<li>in asynchronous, for e.g. s3 permissions are not needed  (unless there is some more data to be extracted from s3) since s3 itself puts the event and invokes lambda. here however, since event source mapper is itself polling for e.g. kinesis, it uses the lambda execution role permissions. so, the execution role needs permissions on kinesis</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>lambda versions - different versions of a function is supported. it is immutable once published, has its own arn, and each version has its own code, configuration, etc</li>\n<li><u>$latest</u> points at the latest versions, and <u>aliases</u> can point to a specific versions</li>\n<li>lambda runs inside a <u>runtime environment</u> (or <u>execution context</u>). when a function is invoked, setup around creating the environment, downloading and installing the <u>deployment package</u>, etc. is needed. this is called a <u>cold start</u>. if we invoke again in quick succession a <u>warm start</u> can happen i.e. the same execution environment gets used. this makes it faster. also, at a time only one invocation can run inside the same runtime environment, so 20 invocations can mean 20 cold starts</li>\n<li>provisioned concurrency - aws can provision such runtime environments for us in advance, useful when we know our load is going to be high in advance</li>\n<li>we can also use the /tmp storage discussed earlier when the same runtime environment gets used for multiple invocations. e.g. some initial downloads needed by our application can be done here</li>\n<li>also, any code outside the function in our code is run only for a new runtime environment. so, we can do things like creating database connections here to save up on time</li>\n<li>so, lambda only needs to invoke the handler in a warm start, and can reuse the existing instance</li>\n<li>so, ideally, or code should be able to handle new environments, but if possible take advantage of existing runtime environments to avoid repeated setup</li>\n<li>lambda@edge - feature of cloudfront which helps run lightweight lambda functions at edge locations. they have some limitations as compared to general lambda</li>\n<li>idea is we can run functions between viewer-cloudfront request, cloudfront-origin request, origin-cloudfront response and cloudfront-viewer response</li>\n<li>my understanding - in lambda, when we set environment variables, we can encrypt them at rest and / or encrypt them in transit. for encryption at rest, we can use the aws managed or customer managed key, but it is still visible in plain sight to everyone for e.g. in console</li>\n<li>encryption in transit and rest? - so, we can instead store the encrypted form of the environment variable in the console, and then use aws sdk (e.g. boto3 library in python) to decrypt this environment variable before using it in the code. so now, the idea is when for e.g. setting an environment variable‚Äôs value, we provide the kms encrypted result in the console</li>\n<li>‚Äúenable helpers for encryption in transit‚Äù - now aws console can help us with this automatically i.e. we provide the actual value, and click on an ‚Äúencrypt‚Äù button. after this, we are asked to select a kms key. after this, the value we entered inside the console is replaced with the encrypted version. we are also given a code snippet to use to decrypt the environment variable before using it</li>\n<li>ec2 throttled exception - caused when not enough private ip addresses are available</li>\n</ul>\n<h1 id=\"sns\" style=\"position:relative;\"><a href=\"#sns\" aria-label=\"sns permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SNS</h1>\n<ul>\n<li>pubsub messaging service</li>\n<li>public service, regionally resilient</li>\n<li>message payloads can be of &#x3C;= 256 kb of size</li>\n<li><u>publishers</u> - put messages on a topic</li>\n<li><u>subscribers</u> receive from a topic. subscribers can be http endpoints, email, sms, sqs, etc</li>\n<li>we can apply <u>filters</u> on subscribers so that they only receive relevant messages</li>\n<li>fan out architecture - multiple sqs queues as subscribers on a single sns topic</li>\n<li>so sns filters + fanout architecture = üíì</li>\n<li>delivery retries are supported</li>\n<li>sse supported</li>\n<li>use topic‚Äôs resource policy for cross account access</li>\n</ul>\n<h1 id=\"step-functions\" style=\"position:relative;\"><a href=\"#step-functions\" aria-label=\"step functions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Step Functions</h1>\n<ul>\n<li>helps chain lambda functions for longer flows to create <u>state machines</u></li>\n<li>maximum duration is 1 year</li>\n<li>standard vs express - express is used for things like streaming data, where duration is upto 5 minutes</li>\n<li>can be started by api gateway, event bridge, etc</li>\n<li>we use asl (amazon state langauge) to create the state machines</li>\n<li>iam roles for permissions</li>\n<li>types of states -\n<ul>\n<li>succeed and fail</li>\n<li>wait - pause step functions for provided time</li>\n<li>choice - take a path based on inputs</li>\n<li>parallel - do certain flows concurrently</li>\n<li>map - accepts a list of items and does something for each of these items</li>\n<li>task - a single unit of work - can be integrated with a lot of aws services like lambda, batch, etc</li>\n</ul>\n</li>\n<li>another service called aws swf (simple workflow service) does something similar?</li>\n</ul>\n<h1 id=\"api-gateway\" style=\"position:relative;\"><a href=\"#api-gateway\" aria-label=\"api gateway permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>API Gateway</h1>\n<ul>\n<li>it supports caching, throttling, cors, transformations, authorization, etc</li>\n<li>429 is the code for throttling</li>\n<li>it calls the backends it connects to ‚Äúintegrations‚Äù. these integrations can be http endpoints (like alb?), lambda, step functions, dynamodb, etc</li>\n<li>can store logs and metrics in cloudwatch</li>\n<li>authentication methods supported - cognito user pools, lambda based (i.e. custom) authorization, etc</li>\n<li>endpoint types - edge optimized (uses cloudfront pop bts), regional (clients in the same region) or private (only accessible from inside a vpc)</li>\n<li>we deploy to stages - e.g. a prod and a dev stage</li>\n<li>so, version 1 of configuration can be deployed to prod and version 2 to dev</li>\n<li>canary deployments - when we enable canary deployments on a stage, any new deployments are made on a canary part of the stage i.e. a subpart and not the entire stage. we can adjust the percentage and then either promote the canary or remove it</li>\n<li>cache - per stage in the api gateway. can be 500mb to 237gb, 0 seconds (i.e. disabled) to 3600 seconds (default is 300 seconds) and can be encrypted</li>\n<li>based on above statements, most configurations are at the stage level</li>\n<li>we basically create ‚Äúresources‚Äù (e.g. /users) and ‚Äúactions‚Äù (e.g. we specify method to be post to represent creating users) inside these resources. we can configure this action to for e.g. invoke lambda. note - resource policy of lambda needs to allow api gateway</li>\n</ul>\n<h1 id=\"sqs\" style=\"position:relative;\"><a href=\"#sqs\" aria-label=\"sqs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SQS</h1>\n<ul>\n<li>managed message queues</li>\n<li>aws public service and regionally resilient</li>\n<li>messages can be 256 kb in size - idea is larger payloads go into s3, and we reference it in sqs messages</li>\n<li>when messages are consumed by a client, the messages are hidden for a time period called message visibility timeout. the idea is that after processing, the client deletes this message from the queue, or else the message reappears on the queue after the visibility timeout</li>\n<li>the message visibility timeout can be configured at a message / queue level</li>\n<li>clients can also use the change visibility timeout api call to change this timeout - my understanding - e.g. the client knows that it needs some more time to handle this message since it is an exception case, so we wouldn‚Äôt want this to fail and the message to reappear on the queue just for another application to pick it up</li>\n<li>dlq - dead letter queues. when even after the retries explained above i.e. message being added to the queue repeatedly after message visibility timeout, these faulty messages can be added to dlq</li>\n<li>the configuration above for dlq is called a redrive policy</li>\n<li>all queues have a retention period for messages i.e. messages are deleted after that. note for dlq - this time does not start when the message was moved to dlq, but when the message was added to the source queue</li>\n<li>note - the retention period can be configurable between 4 days to 14 days</li>\n<li>asg can scale based on the length of queues / lambda invoked from messages on the queue</li>\n<li>short polling vs long polling - in sqs, we are billed per request. so, in short polling, we get 0 or more messages. in long polling, we wait upto 20 seconds. this way, we consume lesser requests and thus save costs</li>\n<li>kms for encryption at rest</li>\n<li>two types - standard and fifo. standard queues guarantee at least once (i.e. can have duplicates) delivery and no order (ordering is best-efforts). fifo queue guarantee exactly once (i.e. no duplicate) delivery and in order</li>\n<li>due to these constraints, fifo queues have a limit of 3000 messages per second with batching and 300 messages per second without batching</li>\n<li>my understanding - for every sqs request, we can put 1-10 messages. this is what batching above refers to</li>\n<li>there are no limits on standard queues</li>\n<li>fifo queue names should have a fifo suffix</li>\n<li>delay queues - postpone delivery of messages to consumers. for the delay duration period, the message would not be visible on the queue. can be configured on a message level. cannot be used on fifo queues</li>\n<li>TODO: question 42 exam 2 - aws prep question - no way for priority, use separate queues</li>\n</ul>\n<h1 id=\"kinesis\" style=\"position:relative;\"><a href=\"#kinesis\" aria-label=\"kinesis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kinesis</h1>\n<ul>\n<li>kinesis data streams - used for large amounts of data. it has persistence - 24 hr rolling window by default from the time of ingestion. so, older data is discarded. this rolling window can be increased upto 365 days. a stream can be divided into shards for scaling. each shard in a stream can ingest at 1mb per second and consume at 2 mb per second. kinesis data records can be 1mb in size\n<ul>\n<li>with kinesis, it is important to think about partitions. records in a partition are ordered, records of a partition go to the same processor thus helping with operations like aggregation and so on</li>\n</ul>\n</li>\n<li>kinesis data firehose - managed service to load data into s3, elasticsearch, splunk, redshift, or http endpoint for persistence (remember these destinations). (note - for redshift, an intermediary bucket between kinesis data firehose and redshift is used). it is not like kinesis data stream which is realtime, it is near realtime (~60 seconds). it can call lambda functions as well for processing. producers can either put data directly into firehose, or put it on kinesis data stream, which kinesis data firehose will then ingest. data is buffered in firehose before delivering i.e. either when 1 mb of data is reached or 60 seconds</li>\n<li>kinesis data analytics - used for data processing using sql. can ingest from kinesis data stream or kinesis data firehose (remember these sources), and optionally pull in reference data from s3. finally, data can be output to kinesis data firehose (but then it becomes near realtime) or kinesis data streams or lambda (for both it stays realtime) (remember these destinations)</li>\n</ul>\n<h1 id=\"cognito\" style=\"position:relative;\"><a href=\"#cognito\" aria-label=\"cognito permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cognito</h1>\n<ul>\n<li>authentication, authorization and user management</li>\n<li>user pools -\n<ul>\n<li>generate jwt tokens which can be accepted directly by products like api gateway</li>\n<li>however, they do not grant access to aws services</li>\n<li>do things like customizable web ui, mfa, user profile management, etc</li>\n<li>can work with other identity providers</li>\n<li>basically it is an identity provider i.e. like a database of users</li>\n</ul>\n</li>\n<li>identity pools -\n<ul>\n<li>unauthenticated identities - offer guest access to aws services e.g. high score board in a game should be visible to everyone irrespective of the authentication status</li>\n<li>exchange an external identity for temporary aws credentials. this external identity can be saml, google etc. social logins, and even user pool. this is called identity federation</li>\n<li>bts, an iam role is used which returns temporary credentials</li>\n</ul>\n</li>\n<li>best case scenario - identity pool is only configured to work with tokens from user pools, and user pools can manage identities from different identity providers like google including itself</li>\n</ul>\n<h1 id=\"aws-glue\" style=\"position:relative;\"><a href=\"#aws-glue\" aria-label=\"aws glue permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>AWS Glue</h1>\n<ul>\n<li>serverless etl i.e. moves and transforms data between source and destination</li>\n<li>supports - s3, jdbc compatible, dynamodb, kinesis data streams, apache kafka</li>\n<li>‚Äúdata catalog‚Äù - collection of metadata about data sources, on a per-region per-account basis. this helps avoid data silos i.e. visibility into data. most aws services like redshift, athena, etc. work with data catalog. this is achieved by configuring crawlers with credentials</li>\n<li>e.g. invoke glue jobs via an event bridge schedule</li>\n<li>‚Äúaws lake formation‚Äù - datalake i.e. centralized repository that contains all our data. uses s3</li>\n<li>‚Äúaws data pipeline‚Äù is a similar product, but it is not serverless</li>\n<li>‚Äúaws emr‚Äù - managed hadoop, spark, hive, pig, etc. basically big data. transform and load data into redshift</li>\n</ul>\n<h1 id=\"amazon-mq\" style=\"position:relative;\"><a href=\"#amazon-mq\" aria-label=\"amazon mq permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Amazon MQ</h1>\n<ul>\n<li>using sns and sqs needs application changes for existing applications migrating to aws</li>\n<li>amazon mq helps use jms protocols like amqp, stomp, mqtt, openwire, etc. are supported</li>\n<li>unlike sqs and sns, it is not a public aws service i.e. runs from inside a vpc</li>\n<li>remember it won‚Äôt have native integration with other services like sns or sqs</li>\n</ul>\n<h1 id=\"amazon-appflow\" style=\"position:relative;\"><a href=\"#amazon-appflow\" aria-label=\"amazon appflow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Amazon AppFlow</h1>\n<ul>\n<li>managed integration service</li>\n<li>connected to source and destinations using ‚Äúconnectors‚Äù and we build ‚Äúflows‚Äù</li>\n<li>e.g. integrate salesforce, sap, slack, etc. with aws services</li>\n</ul>\n<h1 id=\"aws-batch\" style=\"position:relative;\"><a href=\"#aws-batch\" aria-label=\"aws batch permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>AWS Batch</h1>\n<ul>\n<li>helps in executing multiple jobs concurrently</li>\n<li>it takes care of distributing the workload across multiple ec2 instances, scaling up or down based on the demand, and managing the execution environment</li>\n</ul>","frontmatter":{"title":"AWS - Part VIII"}}},"pageContext":{"id":"a3c71bef-ce4c-5080-91ad-c2b00e6354b2"}},"staticQueryHashes":["1037383464","1617985380"]}