{"componentChunkName":"component---src-templates-blog-js","path":"/data-warehouse/","result":{"data":{"markdownRemark":{"fields":{"slug":"/data-warehouse/"},"id":"95e1f94e-54b4-5891-8d97-4421079a48a6","html":"<h1 id=\"about\" style=\"position:relative;\"><a href=\"#about\" aria-label=\"about permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>About</h1>\n<ul>\n<li><strong>oltp</strong> or online transactional processing is used for maintaining data for regular operations. we deal with current data which we can edit and cleanup regularly to keep the database small</li>\n<li><strong>olap</strong> or online analytical processing is used for making better decisions and evaluating operations. we need access to a lot of data including older records and very fast query performance</li>\n<li>data warehouse is a database optimized for olap</li>\n<li>using data warehouses reduces the load on our oltp databases in the long term</li>\n</ul>\n<h1 id=\"data-lake\" style=\"position:relative;\"><a href=\"#data-lake\" aria-label=\"data lake permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Lake</h1>\n<ul>\n<li>we store raw unstructured data in data lake</li>\n<li>data warehouses have transformed data that is user-friendly and optimized for query</li>\n<li>data lakes use big data while data warehouses use databases</li>\n<li>the business purpose of data lakes is not known from the get go unlike in data warehouses</li>\n<li>the idea is to use data warehouses on top of data lakes</li>\n</ul>\n<h1 id=\"data-warehouse-architecture\" style=\"position:relative;\"><a href=\"#data-warehouse-architecture\" aria-label=\"data warehouse architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Warehouse Architecture</h1>\n<ul>\n<li>we extract data from sources into a <strong>staging layer</strong>. we can have trivial transformations along with it</li>\n<li>we then apply much heavier transformations before getting the data to the <strong>core / access / warehouse layer</strong></li>\n<li>sometimes the core layer can get very huge. so we can have <strong>data marts</strong> for each use case which include a subset of data present in the core layers</li>\n<li>the staging layer can be transient i.e. have some method of calculating data which is not present in the core layer and then modify the core layer with the delta accordingly</li>\n<li>the staging layer can also be permanent i.e. maintain a replica of the data in the sources</li>\n<li>data marts can be specialized based on use case e.g. inmemory databases for optimal querying</li>\n<li>note: inmemory databases can result in data loss for e.g. when the system shuts down. this can be prevented via regular snapshots so that the databases have a deterministic point to restore to</li>\n</ul>\n<h1 id=\"ods\" style=\"position:relative;\"><a href=\"#ods\" aria-label=\"ods permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ODS</h1>\n<ul>\n<li>ods or operational data storage is like warehouse, but used when we want data to be updated almost realtime, and not as a part of something like a cron</li>\n<li>to avoid duplicating the effort of data aggregation, it is a common practice to make the ods as the staging layer of the warehouse, i.e. an etl is used to ingest data into the core layer from ods</li>\n</ul>\n<h1 id=\"cubes\" style=\"position:relative;\"><a href=\"#cubes\" aria-label=\"cubes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cubes</h1>\n<ul>\n<li>it uses molap or multidimensional olap, i.e. uses multidimensional tables</li>\n<li>data is not stored as relational datasets but as arrays</li>\n<li>used for optimizing query performance in data mart layers</li>\n<li>it has precalculated aggregated values, thus optimizing the queries</li>\n<li>the language to query cubes is mdx or multidimensional expression</li>\n<li>it is meant for specific use cases and is not meant to be generic</li>\n<li>we should have lesser dimensions to make the most out of a cube’s performance</li>\n</ul>\n<h1 id=\"dimension-modelling\" style=\"position:relative;\"><a href=\"#dimension-modelling\" aria-label=\"dimension modelling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Dimension Modelling</h1>\n<ul>\n<li>the goal is fast data retrieval</li>\n<li>in dimension modelling, our data is organized into <strong>facts</strong> and <strong>dimensions</strong></li>\n<li>fact are measurements (e.g. profit), while dimensions provide context (e.g. year)</li>\n<li>now a meaningful insight can be derived from combining the two, e.g. profits by year</li>\n<li>we can derive multiple insights by combining one fact with different dimensions. this results in something called a <strong>star schema</strong>, where the fact is at the center of the star and the dimensions are at the tips of the star</li>\n<li>fact tables usually consist of a primary key, foreign keys to associate them to dimensions and the actual facts, which are numerical quantities that can be aggregated</li>\n<li>a single row in the fact table is called a <strong>grain</strong>. it has a defined scope e.g. the facts displayed are for a given day for a particular product id</li>\n<li>dimensions help filter, group and label data</li>\n<li>dimension tables consist of a primary key and the actual dimensions which usually cannot be aggregated</li>\n</ul>\n<h1 id=\"facts\" style=\"position:relative;\"><a href=\"#facts\" aria-label=\"facts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Facts</h1>\n<ul>\n<li><strong>additive facts</strong> can be added across all dimensions, while semi additive facts can be added across a few dimensions only and non-additive facts across none of the dimensions</li>\n<li>e.g. of an additive fact can be the number of units of a product sold</li>\n<li>a non-additive fact could be the price of product, since adding it in itself would make no sense without multiplying it by the units sold</li>\n<li>a semi additive fact could be something like a balance that can be a part of different portfolios. adding it across the date dimension for a given portfolio would make no sense, but across different portfolios on a given day could. sometimes, a way to go about semi additive facts can be average i.e. average balance across days for a particular portfolio could make sense</li>\n</ul>\n<p><u>fact table</u> -</p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>portfolio_id</th>\n<th>date_id</th>\n<th>balance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>1</td>\n<td>20221001</td>\n<td>50</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1</td>\n<td>20221002</td>\n<td>100</td>\n</tr>\n<tr>\n<td>1</td>\n<td>1</td>\n<td>20221003</td>\n<td>100</td>\n</tr>\n<tr>\n<td>1</td>\n<td>2</td>\n<td>20221001</td>\n<td>120</td>\n</tr>\n<tr>\n<td>1</td>\n<td>2</td>\n<td>20221002</td>\n<td>170</td>\n</tr>\n<tr>\n<td>1</td>\n<td>2</td>\n<td>20221003</td>\n<td>60</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>✅ <u>adding across portfolio - </u></p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>date_id</th>\n<th>balance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>20221001</td>\n<td>170</td>\n</tr>\n<tr>\n<td>20221002</td>\n<td>270</td>\n</tr>\n<tr>\n<td>20221003</td>\n<td>160</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>❌ <u>adding across date - </u></p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>portfolio_id</th>\n<th>balance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>250</td>\n</tr>\n<tr>\n<td>2</td>\n<td>350</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>✅ <u>averaging across date - </u></p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>portfolio_id</th>\n<th>balance</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>83.33</td>\n</tr>\n<tr>\n<td>2</td>\n<td>116.67</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>nulls are handled by relational databases automatically, but sometimes we might want to convert nulls to 0s nad sometimes not, e.g. average of 50 and null is 50 and not 25, which is what the database does</li>\n<li><strong>transactional fact table</strong> - one transaction or one event, taking place at a specific point of time defines a grain. they usually have a lot of dimensions and are very large i.e. have a lot of rows</li>\n<li><strong>periodic snapshot fact table</strong> - accumulation of transactions over a period of time. they usually don’t have a lot of dimensions and are relatively smaller</li>\n<li><strong>accumulation snapshot fact table</strong> - summarizes a series of transactions / lifetime of a process <u>in one grain</u>, e.g. production, inspection, shipping, and then delivery. usually has a lot of date related dimensions</li>\n<li><strong>factless fact tables</strong> - count total number of records based on a dimension</li>\n<li>as a general practice, try making the grain as fine as possible to allow for flexibility and have more dimensions</li>\n<li><strong>natural</strong> vs <strong>surrogate key</strong> - surrogate keys or artificial keys, are newly generated primary keys for warehouse, since the primary key of the source systems may not be ideal for performance as they can be alphanumeric</li>\n<li>sometimes, if some facts can be calculated from other facts, and they are additive, we can calculate them in the etl and store them in the core layer</li>\n</ul>\n<h1 id=\"dimensions\" style=\"position:relative;\"><a href=\"#dimensions\" aria-label=\"dimensions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Dimensions</h1>\n<ul>\n<li>have primary (preferably surrogate) keys pointed to by the foreign keys in the fact table</li>\n<li>date dimensions contain a lot of attributes like month, day, quarter etc. which can be precalculated</li>\n<li>to avoid losing data in bi, foreign keys in fact tables should not be null, but point to dummy dimensions</li>\n<li>dimension tables can be sometimes denormalized / flattened to help increase query performance</li>\n<li>however, we can normalize the dimension tables by using foreign keys, resulting in a <strong>snowflake schema</strong></li>\n<li>a star schema is actually a snowflake schema with one level</li>\n<li>the tradeoff is between read performance and consistent writes with reduced redundancy</li>\n<li><strong>conformed dimensions</strong> - same dimension tables used by multiple fact tables</li>\n<li>using conformed dimensions can help compare different facts in bi tools</li>\n<li><strong>degenerate dimension</strong> - e.g. we do not need the other attributes of a dimension table. this means the dimension table would only consist of only one attribute, the primary key. so, we can altogether get rid of the dimension table, and the fact table column would now just be a plain attribute and not a foreign key, which we can, for e.g. use for grouping rows. e.g. of a degenerate dimension can be category in the product table</li>\n<li><strong>junk dimension</strong> - dimensions which are like flags, with values which are like enums, e.g. payment mode. we extract all such dimensions to a new dimension table which we call the junk dimension table. if we have 2 indicators, each with 4 possible values, we would have a total of 16 rows in the new dimension table. if this number is very huge, we only store the combinations which have already occurred in a grain before</li>\n<li><strong>role playing dimension</strong> - e.g. we have a grain with an order date and a delivery date. both the foreign keys reference the same dimension table</li>\n</ul>\n<h1 id=\"slowly-changing-dimensions\" style=\"position:relative;\"><a href=\"#slowly-changing-dimensions\" aria-label=\"slowly changing dimensions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Slowly Changing Dimensions</h1>\n<ul>\n<li>scd or slowly changing dimensions are used to represent dimensions that can change with time</li>\n<li><strong>type 0</strong> - dimensions do not change with time, we retain the original data</li>\n<li><strong>type 1</strong> - we just need to update the older values in the dimension table. this can have implications like updating the comparison clause in queries, since the value has changed. note that we also lose the history</li>\n<li><strong>type 2</strong> - we store both the older and the newer values, thus preserving history as well. we can also store attributes like effective and expiration date which allows separating deprecated grains</li>\n<li>we can also mix the types. in our use case, for example, type 1 can be used for a change in product name while type 2 for a change in product category</li>\n<li><strong>type 3</strong> - instead of adding a new row, we add a new column, e.g. previous category. this way, the old bi query does not break, and can be deprecated eventually after on-boarding to the new view</li>\n</ul>\n<h3 id=\"example-of-scd\" style=\"position:relative;\"><a href=\"#example-of-scd\" aria-label=\"example of scd permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Example of SCD</h3>\n<p><u>assume the following existing table, where the updated record is <strong>product(0704, crispy oatmeal biscuit, biscuit)</strong></u></p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>pk</th>\n<th>name</th>\n<th>category</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>0542</td>\n<td>watch</td>\n<td>accessory</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0704</td>\n<td>oatmeal biscuit</td>\n<td>food</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><u>type 1 - </u></p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>pk</th>\n<th>name</th>\n<th>category</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>0542</td>\n<td>watch</td>\n<td>accessory</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0704</td>\n<td>crispy oatmeal biscuit</td>\n<td>biscuit</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><u>type 2 - </u></p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>pk</th>\n<th>name</th>\n<th>category</th>\n<th>effective_date</th>\n<th>expiration_date</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>0542</td>\n<td>watch</td>\n<td>accessory</td>\n<td>20221001</td>\n<td>99990101</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0704</td>\n<td>oatmeal biscuit</td>\n<td>food</td>\n<td>20221001</td>\n<td>20221003</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0704</td>\n<td>crispy oatmeal biscuit</td>\n<td>biscuit</td>\n<td>20221003</td>\n<td>99990101</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><u>type 3 - </u></p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>pk</th>\n<th>name</th>\n<th>prev_name</th>\n<th>category</th>\n<th>prev_category</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>0542</td>\n<td>watch</td>\n<td>-</td>\n<td>accessory</td>\n<td>-</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0704</td>\n<td>crispy oatmeal biscuit</td>\n<td>oatmeal biscuit</td>\n<td>biscuit</td>\n<td>food</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"etl\" style=\"position:relative;\"><a href=\"#etl\" aria-label=\"etl permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ETL</h1>\n<ul>\n<li>the tooling should help connect to data sources, extract the data, transform and clean the data and then finally write the data back to databases</li>\n<li>the loads can be of two types, based on when they are carried out - the <strong>initial load</strong> and the subsequent <strong>delta loads</strong>. the initial load is much slower naturally, and should be carried out at times when the office is not operating, while the delta loads operate based on a regular cron job</li>\n<li>the etl process for both the initial and delta load remains the same, except for the fact that there is a kind of filtering for delta loads which filters out unchanged / old data</li>\n<li>when loading data to the core layer, we may need to insert / update grains. for deleting, instead of completely removing the data, we can use soft delete i.e. use delete markers</li>\n<li>we <strong>consolidate</strong> i.e. combine data from different sources</li>\n<li>basic transformations - <strong>deduplication</strong> i.e. remove duplicates, <strong>filtering</strong> e.g. filter out orders which have status as refunded, <strong>cleanup and integration</strong> e.g. while one system uses M or F for gender, another uses Male or Female, <strong>surrogate key generation</strong> as a replacement of natural key</li>\n<li>advanced transformations - <strong>joining</strong>, <strong>splitting</strong> e.g. location has comma separated address, city, country which can be split into different attributes, <strong>aggregation</strong> e.g. change the granularity of your transaction, by grouping by a value and storing counts, sums etc. for other attributes, <strong>deriving</strong>, e.g. derive different things like quarter, month, etc. of date dimension</li>\n</ul>\n<h1 id=\"elt\" style=\"position:relative;\"><a href=\"#elt\" aria-label=\"elt permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ELT</h1>\n<ul>\n<li>we extract and load data to the core layer at one go. then, we transform using for instance sql queries</li>\n<li>with elt, the target database should have very high performance, since the transformation is being carried out by utilizing compute of the database itself, e.g. snowflake</li>\n<li>now, we have much more flexibility while transforming the data</li>\n<li>it is a bit quicker and easier than etl</li>\n<li>can serve more realtime requirements, since the extracting and loading is much quicker than the entire etl, lesser layers like staging and data marts are involved, etc</li>\n</ul>\n<h1 id=\"optimization\" style=\"position:relative;\"><a href=\"#optimization\" aria-label=\"optimization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Optimization</h1>\n<ul>\n<li>if we use indexes, a full table scan does not happen while filtering data unlike when we do not use indexes</li>\n<li>indexes however make updates slower and use extra storage, so we should not create too many of them</li>\n<li><strong>standard / b tree indices</strong> - it breaks the data into a multilevel tree structure. this index should be used when we have very high cardinality i.e. values across rows are almost unique. it is set on our primary keys by default</li>\n<li><strong>bitmap indices</strong> - usually a good fit for warehouse, where attributes have a relatively lower cardinality. e.g. we create a bitmap for every value, as to on which rows they can occur</li>\n<li><strong>mpp or massive parallel processing</strong> - the queries are broken into parts which run in parallel</li>\n<li>the underlying data can be stored using <strong>shared disk architecture</strong> or <strong>shared nothing architecture</strong>. in shared disk architecture, the underlying storage used by the access layer on top is the same, while in shared nothing architecture, the underlying storage is different as well</li>\n<li><strong>columnar storge</strong> - data is stored column wise instead of row wise i.e. queries only need to process the subset of columns they use and not all the data in a grain</li>\n</ul>\n<p><u>table - </u></p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>payment_mode</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>card</td>\n</tr>\n<tr>\n<td>2</td>\n<td>cash</td>\n</tr>\n<tr>\n<td>3</td>\n<td>cash</td>\n</tr>\n<tr>\n<td>4</td>\n<td>card</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><u>b tree index - </u></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 161px; margin: 5px 0 5px 0 !important;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b0751070bb8aa2c1d0523e046311dbc8/a5ccf/b-tree.drawio.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.32911392405063%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABRklEQVQoz41S2arCQAz1/z+jr/0H9UGhFFHUWlu3lxaXVuxiS93P5QSmjCs3EDJkkpOTpQFNHo+H2PP5jLIs5X06ncRP3+VywfV6xe12E9VzlDR0MPU5n8/RbDbh+z663S6iKMJkMsFyuRSfbdtwHOct7yvg8XjE4XAQGwSBsC2KAlmWIU1TxHEsRX4CvratC5M3mw3+E/uRoZoPLdvcbrfY7/eYzWYyUwpnqeKfGOpA+pstcl55ntfBVVUJaJIkbyyVrQHv97soxTRN9Pv9Okn/U0szDEM2rxOhvs2QMhqN5ER+yXg8fiqigBuched5cF0XrVYLw+FQNrler2XL6jwYN51ORcl+sVhgt9thtVrJRZCEtMxAVhsMBuh0OhLMAgQKwxDtdluWwzgWY5xlWej1ejJj5vICmEvGH1t+PYfX1r752fIf0NNNjyZHMGMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"b tree\"\n        title=\"b tree\"\n        src=\"/static/b0751070bb8aa2c1d0523e046311dbc8/a5ccf/b-tree.drawio.png\"\n        srcset=\"/static/b0751070bb8aa2c1d0523e046311dbc8/c26ae/b-tree.drawio.png 158w,\n/static/b0751070bb8aa2c1d0523e046311dbc8/a5ccf/b-tree.drawio.png 161w\"\n        sizes=\"(max-width: 161px) 100vw, 161px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><u>bitmap index - </u></p>\n<div class=\"table-wrapper\">\n<table>\n<thead>\n<tr>\n<th>payment_mode</th>\n<th>bitmap</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>card</td>\n<td>1001</td>\n</tr>\n<tr>\n<td>cash</td>\n<td>0110</td>\n</tr>\n</tbody>\n</table>\n</div>","frontmatter":{"title":"Data Warehouse"}}},"pageContext":{"id":"95e1f94e-54b4-5891-8d97-4421079a48a6"}},"staticQueryHashes":["1037383464","1617985380"]}