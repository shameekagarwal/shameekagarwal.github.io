{"componentChunkName":"component---src-templates-blog-js","path":"/elastic-stack-part-i/","result":{"data":{"markdownRemark":{"fields":{"slug":"/elastic-stack-part-i/"},"id":"74a6d2b3-c634-5e42-9da9-0543d72eaf4a","html":"<h1 id=\"elastic-stack\" style=\"position:relative;\"><a href=\"#elastic-stack\" aria-label=\"elastic stack permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Elastic Stack</h1>\n<ul>\n<li>elasticsearch - open source analytics and full text search engine. data is stored as json documents in elasticsearch (like rows in rdb). the document contains fields (like columns in rdb). elasticsearch exposes a rest api to interact with it. elasticsearch is built on java and uses lucene underneath</li>\n<li>kibana - visualize data from elasticsearch. kibana actually stores its configuration inside elasticsearch. so, if we spin up a new kibana instance and connect it to elasticsearch, all the dashboard etc. is automatically loaded</li>\n<li>logstash - data processing pipelines. it has input plugins (source data), filter plugins (transform, enrich data) and output plugins (send data to stashes). sources and destinations can be databases, http, files, kafka, elasticsearch, etc. idea is that it works on events. before beats, it worked on logs. each line in a log file is processed as an event. it is parsed using something called a grok pattern, which is basically a regex pattern</li>\n<li>xpack - a family of tools\n<ul>\n<li>adds authentication and authorization, monitor and setup alerting for elastic stack</li>\n<li>graph - analyze relationships in data. uncommonly common traits between different groups shows relevance (e.g. 10 different people using stackoverflow), not commonly common (e.g. 10 people using google). commonly common is just caused due to the popularity of that trait. graph can help us build relations, and integrate it with elasticsearch, kibana, etc</li>\n<li>elasticsearch sql - elasticsearch’s proprietary query dsl can be complex at times, and if we are familiar with sql, we can use it as an alternative</li>\n</ul>\n</li>\n<li>beats - lightweight agents which we install on servers, so they can send data to elasticsearch or logstash. e.g. filebeat for sending log files, metricbeat for system metrics or apm (application performance monitoring), etc</li>\n</ul>\n<h1 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h1>\n<ul>\n<li>we can have multiple nodes in an elasticsearch cluster</li>\n<li>this helps us store a lot of data</li>\n<li>documents in elasticsearch are stored in an index</li>\n<li>when we create a deployment, we are shown the credentials we can use in for e.g. curl below</li>\n<li>use management -> dev tools to open up the kibana console</li>\n<li>to get cluster health - <code class=\"language-text\">GET _cluster/health</code></li>\n<li>to get the nodes of a cluster - <code class=\"language-text\">GET _cat/nodes?v</code> (v means verbose)</li>\n<li>to display all indices, including system ones (for e.g., those created by kibana), use <code class=\"language-text\">GET _cat/indices?v&amp;expand_wildcards=all</code></li>\n<li>this was for elastic cloud - click on manage this deployment from the sidebar, click on copy endpoint for elasticsearch. then, we can use curl like this - <code class=\"language-text\">curl -X GET -u elastic:&lt;the-password> https://elasticsearchdemo.es.us-central1.gcp.cloud.es.io</code></li>\n<li>elasticsearch uses sharding. an index can be divided into multiple shards. it is not that every shard of an index needs to be on a separate node, multiple shards of the same index can exist on the same node</li>\n<li>internally, each shard is an independent lucene index - so, coordinator node has to combine responses from all</li>\n<li>my understanding - an elasticsearch shard has no limits in the storage (apart from the limits of storage it uses internally), but the maximum number of documents stored by a shard can be at most around 2 billion</li>\n<li>apart from increasing capacity to store more data, sharding also helps increase throughput - instead of searching through one shard having 300gb of documents, we can now parallelize our searching across 3 shards each having 100gb of documents</li>\n<li>the default number of shards for an index is 1 (used to be 5), but this can be changed. we can increase the number of shards using split api / decrease the number of shards using shrink api. bts, doing this i think creates a new index and copies over the documents</li>\n<li>fault tolerance - replica shards are created for a primary shard. a primary shard and its replica shards together are called a replication group. replica shards and primary shards are created on different nodes by default</li>\n<li>so basically, number of replication groups = number of primary shards</li>\n<li>the default number for replica shards is 1. so, the total shards for an index by default is 2 (1 primary shard as described above and 1 replica shard)</li>\n<li>replica shards can also serve as read replicas apart from helping with high availability</li>\n<li>elasticsearch supports taking snapshots (at index level or at cluster level) for backup</li>\n<li>there is a setting called <code class=\"language-text\">auto_expand_replicas</code> which can change the number of replicas of a shard depending on the number of nodes</li>\n<li>to get all shards - <code class=\"language-text\">GET /_cat/shards?v</code></li>\n</ul>\n<h1 id=\"node-roles\" style=\"position:relative;\"><a href=\"#node-roles\" aria-label=\"node roles permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Node Roles</h1>\n<ul>\n<li>nodes can have multiple roles</li>\n<li>if a node has a master role, it becomes eligible for being a master. there is an election process which is carried out between all the nodes with the master role</li>\n<li>we can have nodes with data roles as well. my understanding - it is enabled by default on all nodes, and for large clusters, we should have dedicated nodes with master role and others with only the data role</li>\n<li>nodes can have ingest role. nodes with ingest roles can run ingest pipelines, which is a series of processors that are run to transform the data. this functionality is a subset of logstash</li>\n<li>there are roles for classifying nodes as machine learning nodes as well</li>\n<li>nodes can behave as a coordination node, so that they can delegate queries to other nodes. to achieve this, there is no specific role. so for this functionality, all other roles need to be disabled</li>\n<li>when we run <code class=\"language-text\">GET _cat/nodes?v</code>, it shows the nodes with the roles they have <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-nodes.html\">docs</a></li>\n</ul>\n<h1 id=\"basic-crud\" style=\"position:relative;\"><a href=\"#basic-crud\" aria-label=\"basic crud permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Basic Crud</h1>\n<ul>\n<li>deleting an index - <code class=\"language-text\">DELETE pages</code></li>\n<li>to create an index say pages - <code class=\"language-text\">PUT pages</code></li>\n<li>creating an index and specifying the shards -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">PUT products\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"number_of_shards\"</span><span class=\"token operator\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"number_of_replicas\"</span><span class=\"token operator\">:</span> <span class=\"token number\">2</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>indexing documents or adding documents to an index -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST products/_doc\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Coffee Maker\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"price\"</span><span class=\"token operator\">:</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"in_stock\"</span><span class=\"token operator\">:</span> <span class=\"token number\">10</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nan id is automatically generated in this case. we can also specify an id ourselves -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">PUT products/_doc/<span class=\"token number\">100</span>\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Toaster\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"price\"</span><span class=\"token operator\">:</span> <span class=\"token number\">29</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"in_stock\"</span><span class=\"token operator\">:</span> <span class=\"token number\">3</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>getting a document - <code class=\"language-text\">GET products/_doc/100</code></li>\n<li>updating a document (works like patch) -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST products/_update/<span class=\"token number\">100</span>\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"source\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"tags\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"electronics\"</span><span class=\"token punctuation\">]</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nnote - documents in elasticsearch are immutable, so bts, the old document is read, its fields are modified and then it is completely replaced with this new version</li>\n<li>scripted updates -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST products/_update/<span class=\"token number\">100</span>\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"script\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"source\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"ctx._source.in_stock--\"</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nwe can use parameters within the script to make it a bit dynamic -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST products/_update/<span class=\"token number\">100</span>\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"script\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"source\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"ctx._source.in_stock -=  params.quantity\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"params\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"quantity\"</span><span class=\"token operator\">:</span> <span class=\"token number\">4</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nwe can also delete documents using scripts like such (an alternative to using the delete endpoint) -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST products/_update/<span class=\"token number\">100</span>\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"script\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"source\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"\"</span>\"\n      if (ctx._source.in_stock &lt;= <span class=\"token number\">1</span>) <span class=\"token punctuation\">{</span>\n        ctx.op = 'delete';\n      <span class=\"token punctuation\">}</span>\n      ctx._source.in_stock--;\n    <span class=\"token string\">\"\"</span>\"<span class=\"token punctuation\">,</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nupserts - run the script if the document is already present, else create a document with the content of upsert -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST products/_update/<span class=\"token number\">105</span>\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"script\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"source\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"ctx._source.in_stock++\"</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"upsert\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Canvas Shoes\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"in_stock\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>delete a document - <code class=\"language-text\">DELETE products/_doc/105</code></li>\n</ul>\n<h1 id=\"read-and-write-flow\" style=\"position:relative;\"><a href=\"#read-and-write-flow\" aria-label=\"read and write flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Read and Write Flow</h1>\n<ul>\n<li>elasticsearch uses routing to determine the shard of a document. the formula is -\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">shard_num = hash(_routing) % number_of_shards</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\nmy understanding - _routing is the id of the document</li>\n<li>a default routing strategy is used unless we specify one explicitly. we need to take care of issues like hot shards etc. if we specify a custom routing strategy</li>\n<li>how reading a document works - a coordinator node receives the request. based on the routing strategy, it determines the shard number (or the group of shard numbers i.e. the replication group, since we usually have replication enabled). then, it uses ars (adaptive replica selection) to choose the best replica for this read in the replication group. then, the read request is forwarded to it and the coordinator collects the response and finally forwards it back to the client</li>\n<li>how writing a document works - the coordinator node sends the write to the primary shard. the primary shard validates all the types of the document (e.g. field mappings), stores it in its storage and then replicates it to the replica shards. to solve issues related to replication (e.g. replication to some shards succeed and some fail), elasticsearch uses primary terms and sequence numbers</li>\n</ul>\n<h1 id=\"optimistic-concurrency-control\" style=\"position:relative;\"><a href=\"#optimistic-concurrency-control\" aria-label=\"optimistic concurrency control permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Optimistic Concurrency Control</h1>\n<ul>\n<li>primary term - how many times the primary shard has changed (e.g. due to failover etc.)</li>\n<li>sequence number - a counter that is incremented for each write operation. it is at index level, so first document in an index has sequence number as 0, the second one has value 1 and so on</li>\n<li>global checkpoint - the sequence number that all the active shards have been at least aligned upto. so, a new shard that joins the cluster (all the shards of a node that join the cluster) has to refer this and get upto speed</li>\n<li>local checkpoint - belongs to a shard, the last sequence number that the shard saw</li>\n<li>elasticsearch stores a version number. this is not a revision history of documents, so we cannot see what a document looked like in the past</li>\n<li>the <code class=\"language-text\">_version</code> field stores the version and starts at 1. this is incremented everytime the document is modified</li>\n<li>this is called internal versioning</li>\n<li>there is another type of versioning called external versioning. idea is we use versioning in for e.g. our relational database, and want to reuse this version for our elasticsearch system as well\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">PUT products/_doc/<span class=\"token number\">456</span>?version=<span class=\"token number\">24</span>&amp;version_type=external\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Mobile Cover\"</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>optimistic concurrency control - <code class=\"language-text\">POST products/_update/123?if_primary_term=1&amp;if_seq_no=34</code> (recall how all documents we retrieve have these two fields populated). my understanding - the older deprecated way of doing this was using the query parameter <code class=\"language-text\">?version=x</code></li>\n</ul>\n<h1 id=\"bulk-operations\" style=\"position:relative;\"><a href=\"#bulk-operations\" aria-label=\"bulk operations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Bulk Operations</h1>\n<ul>\n<li>updating documents in bulk\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST products/_update_by_query\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"script\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"source\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"ctx._source.in_stock--\"</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\na snapshot of the index is taken first. a query and a bulk update is sent to each shard by the coordinator node. the response of the request above contains a batches key which shows the number of batches used for the bulk update. the query uses a scroll set underneath to iterate through the result set. there are some retries and if the update still fails, the errors are returned. the batches are all updated sequentially. this is not performed in a transaction. so, if there are updates in 3 batches, and the first one succeeds, and the second one fails, the third one is never tried (batches are updated sequentially) and the first one is never rolled back (not a transaction). before updating, it is ensured that the document matches the snapshot that was taken (my understanding - this is like optimistic concurrency control). the version conflicts that occurred are a part of the version_conflicts key in the response. this behavior can be customized using <code class=\"language-text\">\"conflicts\": \"proceed\"</code>, so that if a version conflict occurs, the query is not aborted</li>\n<li>just like the update operation above, we also have a <code class=\"language-text\">_delete_by_query</code> for bulk deletes</li>\n<li>with the bulk api, we can perform multiple actions at once - index, create, update and delete</li>\n<li>bulk api expects data to be formatted using the ndjson specification</li>\n<li>index vs create - in index, the document is either created or replaced if the id already exists, while in create, the document is just created if the id does not exist. similarly, for update, the document needs to exist</li>\n<li>a failed action in the bulk api will not affect others</li>\n<li>syntax - one line contains the action, index name and id, the next line contains the body\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST _bulk\n<span class=\"token punctuation\">{</span> <span class=\"token property\">\"index\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"_index\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"products\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"_id\"</span><span class=\"token operator\">:</span> <span class=\"token number\">200</span> <span class=\"token punctuation\">}</span> <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">{</span> <span class=\"token property\">\"name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Expresso Machine\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"price\"</span><span class=\"token operator\">:</span> <span class=\"token number\">542</span> <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">{</span> <span class=\"token property\">\"create\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"_index\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"products\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"_id\"</span><span class=\"token operator\">:</span> <span class=\"token number\">201</span> <span class=\"token punctuation\">}</span> <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">{</span> <span class=\"token property\">\"name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Coffee Maker\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"price\"</span><span class=\"token operator\">:</span> <span class=\"token number\">299</span> <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">{</span> <span class=\"token property\">\"update\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"_index\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"products\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"_id\"</span><span class=\"token operator\">:</span> <span class=\"token number\">202</span> <span class=\"token punctuation\">}</span> <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">{</span> <span class=\"token property\">\"name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Shoes\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"price\"</span><span class=\"token operator\">:</span> <span class=\"token number\">8</span> <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">{</span> <span class=\"token property\">\"delete\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"_index\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"products\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"_id\"</span><span class=\"token operator\">:</span> <span class=\"token number\">203</span> <span class=\"token punctuation\">}</span> <span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>sending a file in ndjson using curl - <code class=\"language-text\">curl -X POST -u elastic:&lt;the-password> https://elasticsearchdemo.es.us-central1.gcp.cloud.es.io/products/_bulk -H \"Content-Type: application/x-ndjson\" --data-binary \"@products-bulk.json\"</code> (note how the url itself contains the index name, so like in the snippet above, the index name would not be needed)</li>\n</ul>\n<h1 id=\"analysis\" style=\"position:relative;\"><a href=\"#analysis\" aria-label=\"analysis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Analysis</h1>\n<ul>\n<li>analysis is a process carried out on text fields to make them efficient for indexing and searching</li>\n<li>the analyzer consists of a character filter, a tokenizer and a token filter</li>\n<li>character filters - add, remove or modify characters. an analyzer can have 0 or more character filters. they are applied in the order they are specified in. e.g. html_strip will remove the html tags</li>\n<li>tokenizer - an analyzer has one tokenizer. it removes special characters like exclamation marks and splits the sentence into individual tokens</li>\n<li>token filters - add, remove or modify tokens. an analyzer can have 0 or more token filters. e.g. lowercase filter turns all tokens into lowercase</li>\n<li>a lot of options for the three components exist, and we can mix and match them to form a custom analyzer</li>\n<li>the default / standard analyzer - no character filter is used, the tokenizer uses unicode segmentation algorithm. finally, the lowercase token filter is applied. we can see this in action -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST _analyze\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"text\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"two guys walk into a bar, and the third one...DUCKS!\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"standard\"</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nan array is returned, where each element is of the following form -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"token\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"walk\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"start_offset\"</span><span class=\"token operator\">:</span> <span class=\"token number\">9</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"end_offset\"</span><span class=\"token operator\">:</span> <span class=\"token number\">13</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"&lt;ALPHANUM>\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"position\"</span><span class=\"token operator\">:</span> <span class=\"token number\">2</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nwe can specify the components like so (the output is the same as using the standard analyzer)\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST _analyze\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"text\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"two guys walk into a bar, and the third one...DUCKS!\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"char_filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"lowercase\"</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>inverted index - a datastructure to make searching efficient. it maintains a mapping between tokens and the documents which contain them. now, if we search for a token, we can do a simple lookup to find the documents which have that token. they also contain information that help score our lookups</li>\n<li>my understanding - inverted indices are sorted by terms, maybe because algos like binary search can be used</li>\n<li>for fields of types number, geospatial, etc. bkd trees are used, since they can help with efficient range queries</li>\n<li>stemming - reduce words to their root form so that matching works. e.g. if our document contains loved, we would want it to match the search for loves. e.g. of what stemming looks like -\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">i loved drinking bottles of wine on last year's vacation.\ni love drink bottl of wine on last year vacat.</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\nnotice how some words have become worse after stemming (i guess it is what it is). also, not only the documents, but the search query needs to be stemmed as well</li>\n<li>stop words - words like articles that are filtered out during searches since they provide no relevance to scoring. it used to be common to do this during text processing before adding data to elasticsearch, but is insignificant now since elasticsearch’s scoring algorithm is good enough. it is a part of the standard analyzer, but disabled by default\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">i loved drinking bottles of wine on last year's vacation.\ni loved drinking bottles wine last year's vacation.</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n</li>\n</ul>\n<h1 id=\"mapping\" style=\"position:relative;\"><a href=\"#mapping\" aria-label=\"mapping permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Mapping</h1>\n<ul>\n<li>like a schema in relational database, which defines parameters like the type of fields in the document, how these documents are indexed, etc</li>\n<li>there are two approaches for mapping - explicit and dynamic</li>\n<li>we can also use a combination of the two - we explicitly map the existing fields and the new ones which are encountered are added as dynamically mapped fields</li>\n<li>object data type - for a json object. we use the properties key and specify the types of individual fields. note that lucene flattens object types (dot notation) when storing them</li>\n<li>my understanding - the document or the root itself is of object type as well</li>\n<li>keyword data type - used for exact matching, which is useful for filtering, sorting, aggregating, etc\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">POST _analyze\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"text\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"two guys walk into a bar, and the third one...DUCKS!\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"keyword\"</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nthe output of above is as follows -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"tokens\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"token\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"two guys walk into a bar, and the third one...DUCKS!\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"start_offset\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"end_offset\"</span><span class=\"token operator\">:</span> <span class=\"token number\">52</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"word\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"position\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>text data type - for full text searches. i think the concept of standard analyzer above was for this type</li>\n<li>by default, there is no concept of arrays in lucene, so a field can be a single value or an aray of values</li>\n<li>arrays can be nested, and they are flattened before indexing</li>\n<li>e.g. we create a document with one field as an array -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">post reviews/_doc\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"quantity\"</span><span class=\"token operator\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"reviews\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">{</span> <span class=\"token property\">\"author\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"John Doe\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"description\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Good\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span> <span class=\"token property\">\"author\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Jane Doe\"</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"description\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Bad\"</span> <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nwith dot notation, if the field is an array, it would look like this -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"quantity\"</span><span class=\"token operator\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"reviews.author\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"John Doe\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Jane Doe\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"reviews.description\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Good\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Bad\"</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nremember that in elasticsearch, a field can be a single value or a list of values. so, if i run the below -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">get reviews/_search\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"query\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"bool\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"must\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">{</span> <span class=\"token property\">\"match\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"reviews.author\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"John Doe\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">{</span> <span class=\"token property\">\"match\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"reviews.description\"</span><span class=\"token operator\">:</span>  <span class=\"token string\">\"Bad\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nit still returns the document, despite john leaving a review of good. this is because the query to elasticsearch means <code class=\"language-text\">reviews.author</code> should contain john doe and <code class=\"language-text\">reviews.description</code> should contain bad. it does not associate the individual elements of the array, it just treats reviews as type object (confirm this by calling the _mapping endpoint) and now each field can be one or a list of values</li>\n<li>nested data type is used for maintaining the relationship between fields of an object in an array. internally, each element is stored as a separate document</li>\n<li>my conclusion - relying on dynamic mapping for fields being an array of objects is a disaster waiting to happen?</li>\n<li>example of creating an explicit mapping -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">put reviews\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"rating\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"float\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"content\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"text\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"product_id\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"integer\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"author\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"first_name\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"text\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"last_name\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"text\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"email\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"keyword\"</span> <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>we can retrieve the mapping of an index like this - <code class=\"language-text\">get reviews/_mapping</code></li>\n<li>we can use the dot notation when creating mapping, e.g. <code class=\"language-text\">\"author.first_name\": { \"type\": \"text\" }</code></li>\n<li>dates can be of the following formats -\n<ul>\n<li>specially formatted strings - should use iso 8601 format. e.g. 2015-04-15T13:07:41Z, where T separates the date from the time and Z specifies the timezone is utc. we can also specify an offset from utc, e.g. 2015-04-15T13:07:41+01:00. it uses utc timezone by default if nothing is specified</li>\n<li>milliseconds since epoch (1st january, 1970)</li>\n</ul>\n</li>\n<li>internally, it is stored as the milliseconds since epoch after converting to utc</li>\n<li>note - the number of seconds since epoch is also called the unix timestamp. remember to multiply it by 1000 if using this format for datetime, since as we saw above, elasticsearch expects the number to be in milliseconds</li>\n<li>we can skip fields in elasticsearch</li>\n<li>type coercion - e.g. if a field called price has a mapping of type float, and we index a document with <code class=\"language-text\">\"price\": \"7.4\"</code>, the document is indexed successfully. this is because of type coercion. but, if we try indexing a document with <code class=\"language-text\">\"price\": \"7.4m\"</code>, it would fail, since type coercion too cannot convert this to type float</li>\n<li>when we retrieve documents, we get back the original value in <code class=\"language-text\">_source</code> and not the coerced document</li>\n<li>we can disable coercion to ensure errors are thrown if we don’t abide by the mapping</li>\n<li>at the field level when creating an explicit mapping, we can specify <code class=\"language-text\">\"coerce\": false</code>. we can also specify it at an index level and override this default at field level -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\"><span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"index.mapping.coerce\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"amount\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"float\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"coerce\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>if we are sure we do not want to aggregate or sort on a field, we can disable doc_values to save disk space and make some operations more efficient\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\"><span class=\"token property\">\"session_id\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> \n  <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"keyword\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"doc_values\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>just like doc_values above, to save disk space etc., if we don’t need relevance scoring, we can disable norms by setting norms to false</li>\n<li>similarly, we can disable indexing for certain fields by setting index to false. doing this is useful for fields which we only need for metadata and as a part of the response under <code class=\"language-text\">_source</code></li>\n<li>null values are arrays containing nulls, or specifying the field explicitly and setting its value as null. this does not include skipping the field altogether</li>\n<li>since null values cannot be indexed or searched, we can use the null_values field to replace such nullable values with a placeholder value of the same type</li>\n<li>we can add new field mappings, but we cannot change or delete the existing field mappings</li>\n<li>for the reason above, we can use reindexing. it retrieves documents from the old index and then reindexes them using the new index</li>\n<li>we can use a script when reindexing where we can, for e.g. make transformations to the field so that it matches the type of the new index’s field. in the snippet below, we are reindexing to change mapping of product_id from float to string, and along with this, we use a script so that even when retrieving documents, this change is reflected in <code class=\"language-text\">_source</code> (so that type coercion does not have to kick in)\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">post _reindex\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"source\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"index\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"reviews\"</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"dest\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"index\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"reviews_new\"</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"script\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"source\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"\"</span>\"\n      if (ctx._source.product_id != <span class=\"token null keyword\">null</span>) <span class=\"token punctuation\">{</span>\n        ctx._source.product_id = ctx._source.product_id.toString();\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token string\">\"\"</span>\"\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>we can also only reindex a subset of the documents as well\n<ul>\n<li>by specifying filtering logic using <code class=\"language-text\">source.query</code></li>\n<li>by setting <code class=\"language-text\">ctx.op = \"noop\"</code> in the script. this will be slower since it is run for all documents now, but can sometimes be the only option if our filtering logic is complex</li>\n</ul>\n</li>\n<li>we cannot delete field mappings. the idea is that when reindexing, we want to remove some fields\n<ul>\n<li>we specify the fields we would like to populate in the new index using the <code class=\"language-text\">source._source</code> field</li>\n<li>in the script, we can have a statement like this - <code class=\"language-text\">ctx._source.remove(\"content\")</code></li>\n</ul>\n</li>\n<li>we can set <code class=\"language-text\">ctx.noop = \"delete\"</code> so that the document from the destination index is deleted. e.g. a document for an id already exists in the destination index, and there is a document in the source index with the same id</li>\n<li>we can have aliases for fields (like alternate names). after updating an alias, queries etc. can use both the alias and the original field name\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">put reviews/_mapping\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"comment\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"alias\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"path\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"content\"</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>multi field mappings - multiple mappings for a field. e.g. we need to have both aggregations and search functionality for a field. all the relevant multiple indexes would be created for the field\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">put recipe\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"ingredients\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"fields\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"keyword\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"keyword\"</span>\n          <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>index templates can be used to apply the same settings and mappings to some index patterns, which can be specified using wildcards. beats uses this feature internally as well. e.g. it is common to have an index for each day’s access log, e.g. access-logs-2023-05-03, access-logs-2023-05-04, and so on. i think we can override these when creating indexes (for settings) or mappings of indexes ourselves\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">put _template/access-logs\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"index_patterns\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"access-logs-*\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"number_of_shards\"</span><span class=\"token operator\">:</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"index.mapping.coerce\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"@timestamp\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"date\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"url.original\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"keyword\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"http.request.referrer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"keyword\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"http.response.status_code\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"long\"</span> <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>ecs - elastic common search - a specification around how some common fields should be mapped. in ecs, documents are called events. it has fields for common use cases like timestamp. <a href=\"https://www.elastic.co/guide/en/ecs/current/index.html\">docs</a>. if we use products like filebeat, metricbeat, etc., we automatically make use of ecs</li>\n<li>dynamic mapping - when we add a document to an index with fields not existing in the mapping of the index, elasticsearch generates mapping for these fields automatically</li>\n<li>the ignore_above parameter, in for e.g. the fields of type keyword indicates that for strings longer than 256 chars, an inverted index will not be generated. it can help in optimizing storage, because it is not common to have an index and perform things like aggregations, sorting, etc. for large values</li>\n<li>tools like date detection and numeric detection are used to coerce strings into appropriate types</li>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-field-mapping.html\">the rules</a> of dynamic mapping</li>\n<li>disabling dynamic mapping -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">put people\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"dynamic\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"first_name\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"text\"</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\nhowever, when i run the query below to add a document, it does not fail -\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">post people/_doc\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"first_name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"john\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"last_name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"doe\"</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span></span></pre></div>\non running <code class=\"language-text\">get people/_mapping</code>, i still see only the first_name field mapped. when i run <code class=\"language-text\">get people/_search</code> by itself, i can see the document with the last_name populated. however, when i run the query below to search by last name, it does not return the document. this is because the inverted index for the new field was not created, as fetching the mapping indicates\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-json line-numbers\"><code class=\"language-json\">get people/_search\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"query\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"match\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"last_name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"andersen\"</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n</li>\n<li>if we want indexing of a document with unmapped fields to fail, we need to set <code class=\"language-text\">dynamic</code> to <code class=\"language-text\">strict</code></li>\n<li>remember that even with dynamic mapping set to strict, we can leave out fields. my understanding - elasticsearch at its core is that a field can have 0 or any number of values</li>\n<li>dynamic mapping uses inheritance as well, so we can choose to override the dynamic mapping property differently for nested fields of type object</li>\n<li>i think numeric detection is disabled by default, we can change this by setting the <code class=\"language-text\">numeric_detection</code> to true just like we set <code class=\"language-text\">dynamic</code>. date detection is enabled by default, and its properties can be configured as well</li>\n</ul>\n<h3 id=\"some-recommendations\" style=\"position:relative;\"><a href=\"#some-recommendations\" aria-label=\"some recommendations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Some Recommendations</h3>\n<ul>\n<li>dynamic mapping is not a good idea</li>\n<li>prefer setting dynamic to “strict”</li>\n<li>use text or keyword mapping for strings based on requirement, do not use both</li>\n<li>disable coercion</li>\n<li>use correct numeric type for number - integer vs long, float vs double</li>\n<li>be mindful of doc_values, norms and index. such features are useful when storing a lot of documents</li>\n</ul>","frontmatter":{"title":"Elastic Stack - Part I"}}},"pageContext":{"id":"74a6d2b3-c634-5e42-9da9-0543d72eaf4a"}},"staticQueryHashes":["1037383464","1617985380"]}